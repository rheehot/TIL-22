(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{220:function(t,e,r){"use strict";r.r(e);var i=r(0),a=Object(i.a)({},(function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("div",{staticClass:"content"},[t._m(0),t._m(1),t._m(2),r("p",[t._v("사이킷런 튜토리얼에서는 "),r("a",{attrs:{href:"http://scikit-learn.org/stable/tutorial/machine_learning_map/",target:"_blank",rel:"noopener noreferrer"}},[t._v("모델 선택을 위한 플로우 차트"),r("OutboundLink")],1),t._v("를 제공하고 있다.")]),r("p",[t._v("학습에 사용되는 데이터 수, 연속/비연속, 정답 레이블 존재유무 등이 핵심요소이다. 특히 데이터 수가 너무 많을 때는 온라인 학습 알고리즘을 이용할 수 있다.")]),t._m(3),t._m(4),t._m(5),r("p",[t._v("살펴볼 분류 알고리즘은 다음과 같다.")]),t._m(6),r("p",[t._v("퍼셉트론, 로지스틱 회귀, SVM, 신경망은 두 클래스의 경계면에 대한 함수를 학습한다. 경계면 함수란 두 클래스를 구분하는 초평면을 이야기하며, 결정 경계(Decision Boundary)라고도 한다. k-NN은 거리를 기준으로 판단하며, 나머지 셋은 트리 구조로 규칙집합을 학습한다.")]),r("p",[t._v("이외에도 텍스트 분류에 많이 사용되는 나이브 베이즈나 음성인식에 오랫동안 사용된 은닉 마르코프 모델(HMM) 등도 있다. 이들 알고리즘은 데이터에 잠재된 확률분포를 추정하는 방법으로 모델링한다.")]),t._m(7),r("p",[t._v("(단순) 퍼셉트론은 입력벡터에 가중치 벡터를 곱한 합을 기준으로 이진 분류하는 알고리즘이다. 퍼셉트론은 온라인 학습 방식을 취하고, 성능은 보통이지만, 학습이 빠르다. 과적합되기 쉬우며, 선형 분리 가능한 문제만 풀 수 있다.")]),r("p",[t._v("온라인 학습은 데이터를 하나씩 넣으면서 학습하는 방식이고, 배치학습은 데이터를 한꺼번에 입력해서 최적화하는 방식이다. 과적합은 특성수를 줄이거나, 규제항을 도입하거나, 더 간단한 알고리즘을 적용함으로써 방지할 수 있는데, 전통적인 퍼셉트론에서는 과적합을 억제하는 구조가 없다.")]),r("p",[t._v("과적합과 반대되는 현상은 과소적합(underfitting)이라고 하는데, 도메인의 고유한 특징을 포함하지 못했거나, 표현력이 낮거나, 규제항이 지나치게 강한 경우에 발생한다.")]),r("p",[t._v("또한 선형 분리 가능(linearly separable)한 문제만 풀수 있는데, 대표적으로 배타적 논리합(exclusive or, XOR) 문제를 풀지 못한다. 이를 제대로 풀지 못하는 예제는 깃헙 저장소의 "),r("a",{attrs:{href:"https://github.com/flourscent/ml-at-work/blob/master/chap02/Decision_boundary.ipynb",target:"_blank",rel:"noopener noreferrer"}},[t._v("chap02/Decision_boundary.ipynb"),r("OutboundLink")],1),t._v("에서 확인할 수 있다.")])])}),[function(){var t=this.$createElement,e=this._self._c||t;return e("h1",{attrs:{id:"머신러닝으로-할-수-있는-일"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#머신러닝으로-할-수-있는-일","aria-hidden":"true"}},[this._v("#")]),this._v(" 머신러닝으로 할 수 있는 일")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"머신러닝-알고리즘-선택-방법"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#머신러닝-알고리즘-선택-방법","aria-hidden":"true"}},[this._v("#")]),this._v(" 머신러닝 알고리즘 선택 방법")])},function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("ul",[r("li",[t._v("분류")]),r("li",[t._v("회귀")]),r("li",[t._v("군집화")]),r("li",[t._v("차원 축소")]),r("li",[t._v("그 외\n"),r("ul",[r("li",[t._v("추천")]),r("li",[t._v("이상 탐지")]),r("li",[t._v("고빈도 패턴 마이닝")]),r("li",[t._v("강화 학습")])])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"사이킷런이-제공하는-온라인-학습-알고리즘"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#사이킷런이-제공하는-온라인-학습-알고리즘","aria-hidden":"true"}},[this._v("#")]),this._v(" 사이킷런이 제공하는 온라인 학습 알고리즘")])},function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("p",[t._v("사이킷런은 분류용으로 "),r("code",[t._v("SGDClassifier")]),t._v("와 회귀용 "),r("code",[t._v("SGDRegressor")]),t._v("를 제공한다. 손실함수와 규제항에 따라 SVM, 로지스틱 회귀, SVR과 비슷한 성능을 보여준다. 온라인 학습이 가능한 선형 분리기로는 Passive Agressive 알고리즘을 제공하지만, SCW나 AROW와 같은 비교적 최신 알고리즘은 제공하지 않는다. "),r("code",[t._v("0.18.0")]),t._v("부터 신경망용 ADAM 구현이 추가되었으며, "),r("code",[t._v("MLPClassifier")]),t._v(" 클래스에서 이용할 수 있다.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"분류"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#분류","aria-hidden":"true"}},[this._v("#")]),this._v(" 분류")])},function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("ul",[r("li",[t._v("퍼셉트론")]),r("li",[t._v("로지스틱 회귀")]),r("li",[t._v("서포트 벡터 머신")]),r("li",[t._v("신경망")]),r("li",[t._v("k-최근접 이웃(k-NN)")]),r("li",[t._v("결정 트리")]),r("li",[t._v("랜덤 포레스트")]),r("li",[t._v("경사 부스팅 결정 트리(GBDT)")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"퍼셉트론"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#퍼셉트론","aria-hidden":"true"}},[this._v("#")]),this._v(" 퍼셉트론")])}],!1,null,null,null);e.default=a.exports}}]);